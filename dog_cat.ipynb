{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "train_set = datasets.ImageFolder(root='data/001/train',transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "test_set = datasets.ImageFolder(root='data/001/test',transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, criterion, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {:2d} [{:5d}/{} ({:2.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, criterion, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target).item() \n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  0 [    0/4654 (0%)]\tLoss: 2.488176\n",
      "Train Epoch:  0 [   40/4654 (1%)]\tLoss: 3.111938\n",
      "Train Epoch:  0 [   80/4654 (2%)]\tLoss: 2.292539\n",
      "Train Epoch:  0 [  120/4654 (3%)]\tLoss: 2.431450\n",
      "Train Epoch:  0 [  160/4654 (3%)]\tLoss: 2.121452\n",
      "Train Epoch:  0 [  200/4654 (4%)]\tLoss: 3.081182\n",
      "Train Epoch:  0 [  240/4654 (5%)]\tLoss: 2.206930\n",
      "Train Epoch:  0 [  280/4654 (6%)]\tLoss: 2.237951\n",
      "Train Epoch:  0 [  320/4654 (7%)]\tLoss: 1.683698\n",
      "Train Epoch:  0 [  360/4654 (8%)]\tLoss: 1.622422\n",
      "Train Epoch:  0 [  400/4654 (9%)]\tLoss: 1.441098\n",
      "Train Epoch:  0 [  440/4654 (9%)]\tLoss: 1.389880\n",
      "Train Epoch:  0 [  480/4654 (10%)]\tLoss: 1.511540\n",
      "Train Epoch:  0 [  520/4654 (11%)]\tLoss: 1.600518\n",
      "Train Epoch:  0 [  560/4654 (12%)]\tLoss: 1.511854\n",
      "Train Epoch:  0 [  600/4654 (13%)]\tLoss: 2.052223\n",
      "Train Epoch:  0 [  640/4654 (14%)]\tLoss: 1.312982\n",
      "Train Epoch:  0 [  680/4654 (15%)]\tLoss: 2.546352\n",
      "Train Epoch:  0 [  720/4654 (15%)]\tLoss: 2.311950\n",
      "Train Epoch:  0 [  760/4654 (16%)]\tLoss: 0.879257\n",
      "Train Epoch:  0 [  800/4654 (17%)]\tLoss: 1.106587\n",
      "Train Epoch:  0 [  840/4654 (18%)]\tLoss: 1.718262\n",
      "Train Epoch:  0 [  880/4654 (19%)]\tLoss: 1.899204\n",
      "Train Epoch:  0 [  920/4654 (20%)]\tLoss: 1.564667\n",
      "Train Epoch:  0 [  960/4654 (21%)]\tLoss: 1.327517\n",
      "Train Epoch:  0 [ 1000/4654 (21%)]\tLoss: 1.642734\n",
      "Train Epoch:  0 [ 1040/4654 (22%)]\tLoss: 2.202892\n",
      "Train Epoch:  0 [ 1080/4654 (23%)]\tLoss: 2.420786\n",
      "Train Epoch:  0 [ 1120/4654 (24%)]\tLoss: 1.534711\n",
      "Train Epoch:  0 [ 1160/4654 (25%)]\tLoss: 1.885755\n",
      "Train Epoch:  0 [ 1200/4654 (26%)]\tLoss: 1.460624\n",
      "Train Epoch:  0 [ 1240/4654 (27%)]\tLoss: 0.608346\n",
      "Train Epoch:  0 [ 1280/4654 (27%)]\tLoss: 2.342152\n",
      "Train Epoch:  0 [ 1320/4654 (28%)]\tLoss: 1.759976\n",
      "Train Epoch:  0 [ 1360/4654 (29%)]\tLoss: 1.165107\n",
      "Train Epoch:  0 [ 1400/4654 (30%)]\tLoss: 1.752546\n",
      "Train Epoch:  0 [ 1440/4654 (31%)]\tLoss: 1.057253\n",
      "Train Epoch:  0 [ 1480/4654 (32%)]\tLoss: 0.432203\n",
      "Train Epoch:  0 [ 1520/4654 (33%)]\tLoss: 1.802416\n",
      "Train Epoch:  0 [ 1560/4654 (34%)]\tLoss: 2.240228\n",
      "Train Epoch:  0 [ 1600/4654 (34%)]\tLoss: 1.818332\n",
      "Train Epoch:  0 [ 1640/4654 (35%)]\tLoss: 0.580590\n",
      "Train Epoch:  0 [ 1680/4654 (36%)]\tLoss: 1.890657\n",
      "Train Epoch:  0 [ 1720/4654 (37%)]\tLoss: 0.895334\n",
      "Train Epoch:  0 [ 1760/4654 (38%)]\tLoss: 1.419285\n",
      "Train Epoch:  0 [ 1800/4654 (39%)]\tLoss: 0.338035\n",
      "Train Epoch:  0 [ 1840/4654 (40%)]\tLoss: 1.829379\n",
      "Train Epoch:  0 [ 1880/4654 (40%)]\tLoss: 0.521254\n",
      "Train Epoch:  0 [ 1920/4654 (41%)]\tLoss: 1.446175\n",
      "Train Epoch:  0 [ 1960/4654 (42%)]\tLoss: 1.016082\n",
      "Train Epoch:  0 [ 2000/4654 (43%)]\tLoss: 0.544324\n",
      "Train Epoch:  0 [ 2040/4654 (44%)]\tLoss: 1.652654\n",
      "Train Epoch:  0 [ 2080/4654 (45%)]\tLoss: 1.294798\n",
      "Train Epoch:  0 [ 2120/4654 (46%)]\tLoss: 2.856164\n",
      "Train Epoch:  0 [ 2160/4654 (46%)]\tLoss: 1.088372\n",
      "Train Epoch:  0 [ 2200/4654 (47%)]\tLoss: 1.904755\n",
      "Train Epoch:  0 [ 2240/4654 (48%)]\tLoss: 0.850168\n",
      "Train Epoch:  0 [ 2280/4654 (49%)]\tLoss: 1.393039\n",
      "Train Epoch:  0 [ 2320/4654 (50%)]\tLoss: 1.672218\n",
      "Train Epoch:  0 [ 2360/4654 (51%)]\tLoss: 0.605851\n",
      "Train Epoch:  0 [ 2400/4654 (52%)]\tLoss: 0.933604\n",
      "Train Epoch:  0 [ 2440/4654 (52%)]\tLoss: 1.921103\n",
      "Train Epoch:  0 [ 2480/4654 (53%)]\tLoss: 0.762580\n",
      "Train Epoch:  0 [ 2520/4654 (54%)]\tLoss: 1.601562\n",
      "Train Epoch:  0 [ 2560/4654 (55%)]\tLoss: 2.335562\n",
      "Train Epoch:  0 [ 2600/4654 (56%)]\tLoss: 1.154013\n",
      "Train Epoch:  0 [ 2640/4654 (57%)]\tLoss: 0.123746\n",
      "Train Epoch:  0 [ 2680/4654 (58%)]\tLoss: 0.647306\n",
      "Train Epoch:  0 [ 2720/4654 (58%)]\tLoss: 0.864059\n",
      "Train Epoch:  0 [ 2760/4654 (59%)]\tLoss: 0.358499\n",
      "Train Epoch:  0 [ 2800/4654 (60%)]\tLoss: 1.289395\n",
      "Train Epoch:  0 [ 2840/4654 (61%)]\tLoss: 1.557054\n",
      "Train Epoch:  0 [ 2880/4654 (62%)]\tLoss: 1.922019\n",
      "Train Epoch:  0 [ 2920/4654 (63%)]\tLoss: 1.438593\n",
      "Train Epoch:  0 [ 2960/4654 (64%)]\tLoss: 1.938700\n",
      "Train Epoch:  0 [ 3000/4654 (64%)]\tLoss: 1.704782\n",
      "Train Epoch:  0 [ 3040/4654 (65%)]\tLoss: 1.568769\n",
      "Train Epoch:  0 [ 3080/4654 (66%)]\tLoss: 0.785226\n",
      "Train Epoch:  0 [ 3120/4654 (67%)]\tLoss: 2.110838\n",
      "Train Epoch:  0 [ 3160/4654 (68%)]\tLoss: 0.470483\n",
      "Train Epoch:  0 [ 3200/4654 (69%)]\tLoss: 1.827210\n",
      "Train Epoch:  0 [ 3240/4654 (70%)]\tLoss: 0.987412\n",
      "Train Epoch:  0 [ 3280/4654 (70%)]\tLoss: 1.541688\n",
      "Train Epoch:  0 [ 3320/4654 (71%)]\tLoss: 0.305096\n",
      "Train Epoch:  0 [ 3360/4654 (72%)]\tLoss: 0.956237\n",
      "Train Epoch:  0 [ 3400/4654 (73%)]\tLoss: 0.992684\n",
      "Train Epoch:  0 [ 3440/4654 (74%)]\tLoss: 2.206359\n",
      "Train Epoch:  0 [ 3480/4654 (75%)]\tLoss: 1.764995\n",
      "Train Epoch:  0 [ 3520/4654 (76%)]\tLoss: 1.653036\n",
      "Train Epoch:  0 [ 3560/4654 (76%)]\tLoss: 1.151536\n",
      "Train Epoch:  0 [ 3600/4654 (77%)]\tLoss: 1.689120\n",
      "Train Epoch:  0 [ 3640/4654 (78%)]\tLoss: 1.677799\n",
      "Train Epoch:  0 [ 3680/4654 (79%)]\tLoss: 1.569946\n",
      "Train Epoch:  0 [ 3720/4654 (80%)]\tLoss: 0.911836\n",
      "Train Epoch:  0 [ 3760/4654 (81%)]\tLoss: 0.808991\n",
      "Train Epoch:  0 [ 3800/4654 (82%)]\tLoss: 0.625742\n",
      "Train Epoch:  0 [ 3840/4654 (82%)]\tLoss: 0.908709\n",
      "Train Epoch:  0 [ 3880/4654 (83%)]\tLoss: 1.539769\n",
      "Train Epoch:  0 [ 3920/4654 (84%)]\tLoss: 1.657909\n",
      "Train Epoch:  0 [ 3960/4654 (85%)]\tLoss: 0.545814\n",
      "Train Epoch:  0 [ 4000/4654 (86%)]\tLoss: 1.000114\n",
      "Train Epoch:  0 [ 4040/4654 (87%)]\tLoss: 0.742385\n",
      "Train Epoch:  0 [ 4080/4654 (88%)]\tLoss: 1.032946\n",
      "Train Epoch:  0 [ 4120/4654 (88%)]\tLoss: 0.865269\n",
      "Train Epoch:  0 [ 4160/4654 (89%)]\tLoss: 2.227209\n",
      "Train Epoch:  0 [ 4200/4654 (90%)]\tLoss: 0.502079\n",
      "Train Epoch:  0 [ 4240/4654 (91%)]\tLoss: 0.506400\n",
      "Train Epoch:  0 [ 4280/4654 (92%)]\tLoss: 1.125913\n",
      "Train Epoch:  0 [ 4320/4654 (93%)]\tLoss: 1.647401\n",
      "Train Epoch:  0 [ 4360/4654 (94%)]\tLoss: 1.417619\n",
      "Train Epoch:  0 [ 4400/4654 (95%)]\tLoss: 0.692981\n",
      "Train Epoch:  0 [ 4440/4654 (95%)]\tLoss: 1.139408\n",
      "Train Epoch:  0 [ 4480/4654 (96%)]\tLoss: 1.612021\n",
      "Train Epoch:  0 [ 4520/4654 (97%)]\tLoss: 0.962957\n",
      "Train Epoch:  0 [ 4560/4654 (98%)]\tLoss: 1.429404\n",
      "Train Epoch:  0 [ 4600/4654 (99%)]\tLoss: 2.559438\n",
      "Train Epoch:  0 [ 4640/4654 (100%)]\tLoss: 1.330255\n",
      "\n",
      "Test set: Average loss: 0.4459, Accuracy: 1329/1552 (86%)\n",
      "\n",
      "Train Epoch:  1 [    0/4654 (0%)]\tLoss: 0.868186\n",
      "Train Epoch:  1 [   40/4654 (1%)]\tLoss: 1.454282\n",
      "Train Epoch:  1 [   80/4654 (2%)]\tLoss: 1.465329\n",
      "Train Epoch:  1 [  120/4654 (3%)]\tLoss: 1.838757\n",
      "Train Epoch:  1 [  160/4654 (3%)]\tLoss: 1.337183\n",
      "Train Epoch:  1 [  200/4654 (4%)]\tLoss: 0.185403\n",
      "Train Epoch:  1 [  240/4654 (5%)]\tLoss: 1.403488\n",
      "Train Epoch:  1 [  280/4654 (6%)]\tLoss: 0.959059\n",
      "Train Epoch:  1 [  320/4654 (7%)]\tLoss: 0.730960\n",
      "Train Epoch:  1 [  360/4654 (8%)]\tLoss: 1.509513\n",
      "Train Epoch:  1 [  400/4654 (9%)]\tLoss: 0.912449\n",
      "Train Epoch:  1 [  440/4654 (9%)]\tLoss: 0.236055\n",
      "Train Epoch:  1 [  480/4654 (10%)]\tLoss: 0.752952\n",
      "Train Epoch:  1 [  520/4654 (11%)]\tLoss: 0.452290\n",
      "Train Epoch:  1 [  560/4654 (12%)]\tLoss: 0.171647\n",
      "Train Epoch:  1 [  600/4654 (13%)]\tLoss: 0.870575\n",
      "Train Epoch:  1 [  640/4654 (14%)]\tLoss: 2.003245\n",
      "Train Epoch:  1 [  680/4654 (15%)]\tLoss: 1.596603\n",
      "Train Epoch:  1 [  720/4654 (15%)]\tLoss: 0.658418\n",
      "Train Epoch:  1 [  760/4654 (16%)]\tLoss: 1.783756\n",
      "Train Epoch:  1 [  800/4654 (17%)]\tLoss: 0.339221\n",
      "Train Epoch:  1 [  840/4654 (18%)]\tLoss: 1.182705\n",
      "Train Epoch:  1 [  880/4654 (19%)]\tLoss: 0.769135\n",
      "Train Epoch:  1 [  920/4654 (20%)]\tLoss: 0.714953\n",
      "Train Epoch:  1 [  960/4654 (21%)]\tLoss: 0.309390\n",
      "Train Epoch:  1 [ 1000/4654 (21%)]\tLoss: 1.695743\n",
      "Train Epoch:  1 [ 1040/4654 (22%)]\tLoss: 0.726169\n",
      "Train Epoch:  1 [ 1080/4654 (23%)]\tLoss: 1.491056\n",
      "Train Epoch:  1 [ 1120/4654 (24%)]\tLoss: 0.533726\n",
      "Train Epoch:  1 [ 1160/4654 (25%)]\tLoss: 0.725363\n",
      "Train Epoch:  1 [ 1200/4654 (26%)]\tLoss: 2.048550\n",
      "Train Epoch:  1 [ 1240/4654 (27%)]\tLoss: 0.588925\n",
      "Train Epoch:  1 [ 1280/4654 (27%)]\tLoss: 1.140968\n",
      "Train Epoch:  1 [ 1320/4654 (28%)]\tLoss: 2.905590\n",
      "Train Epoch:  1 [ 1360/4654 (29%)]\tLoss: 1.889739\n",
      "Train Epoch:  1 [ 1400/4654 (30%)]\tLoss: 0.452424\n",
      "Train Epoch:  1 [ 1440/4654 (31%)]\tLoss: 1.045982\n",
      "Train Epoch:  1 [ 1480/4654 (32%)]\tLoss: 0.896482\n",
      "Train Epoch:  1 [ 1520/4654 (33%)]\tLoss: 0.667886\n",
      "Train Epoch:  1 [ 1560/4654 (34%)]\tLoss: 0.566901\n",
      "Train Epoch:  1 [ 1600/4654 (34%)]\tLoss: 1.945341\n",
      "Train Epoch:  1 [ 1640/4654 (35%)]\tLoss: 2.598712\n",
      "Train Epoch:  1 [ 1680/4654 (36%)]\tLoss: 2.144698\n",
      "Train Epoch:  1 [ 1720/4654 (37%)]\tLoss: 0.748005\n",
      "Train Epoch:  1 [ 1760/4654 (38%)]\tLoss: 1.081050\n",
      "Train Epoch:  1 [ 1800/4654 (39%)]\tLoss: 0.210333\n",
      "Train Epoch:  1 [ 1840/4654 (40%)]\tLoss: 3.225943\n",
      "Train Epoch:  1 [ 1880/4654 (40%)]\tLoss: 1.499290\n",
      "Train Epoch:  1 [ 1920/4654 (41%)]\tLoss: 0.434321\n",
      "Train Epoch:  1 [ 1960/4654 (42%)]\tLoss: 1.133635\n",
      "Train Epoch:  1 [ 2000/4654 (43%)]\tLoss: 0.956145\n",
      "Train Epoch:  1 [ 2040/4654 (44%)]\tLoss: 1.195104\n",
      "Train Epoch:  1 [ 2080/4654 (45%)]\tLoss: 1.293291\n",
      "Train Epoch:  1 [ 2120/4654 (46%)]\tLoss: 1.111738\n",
      "Train Epoch:  1 [ 2160/4654 (46%)]\tLoss: 0.947321\n",
      "Train Epoch:  1 [ 2200/4654 (47%)]\tLoss: 1.135656\n",
      "Train Epoch:  1 [ 2240/4654 (48%)]\tLoss: 1.259184\n",
      "Train Epoch:  1 [ 2280/4654 (49%)]\tLoss: 0.931928\n",
      "Train Epoch:  1 [ 2320/4654 (50%)]\tLoss: 0.523477\n",
      "Train Epoch:  1 [ 2360/4654 (51%)]\tLoss: 0.954087\n",
      "Train Epoch:  1 [ 2400/4654 (52%)]\tLoss: 0.418489\n",
      "Train Epoch:  1 [ 2440/4654 (52%)]\tLoss: 0.858273\n",
      "Train Epoch:  1 [ 2480/4654 (53%)]\tLoss: 0.703562\n",
      "Train Epoch:  1 [ 2520/4654 (54%)]\tLoss: 0.669224\n",
      "Train Epoch:  1 [ 2560/4654 (55%)]\tLoss: 0.500475\n",
      "Train Epoch:  1 [ 2600/4654 (56%)]\tLoss: 1.594882\n",
      "Train Epoch:  1 [ 2640/4654 (57%)]\tLoss: 0.988089\n",
      "Train Epoch:  1 [ 2680/4654 (58%)]\tLoss: 1.910779\n",
      "Train Epoch:  1 [ 2720/4654 (58%)]\tLoss: 0.478786\n",
      "Train Epoch:  1 [ 2760/4654 (59%)]\tLoss: 0.928998\n",
      "Train Epoch:  1 [ 2800/4654 (60%)]\tLoss: 1.345989\n",
      "Train Epoch:  1 [ 2840/4654 (61%)]\tLoss: 0.369252\n",
      "Train Epoch:  1 [ 2880/4654 (62%)]\tLoss: 0.533523\n",
      "Train Epoch:  1 [ 2920/4654 (63%)]\tLoss: 0.785294\n",
      "Train Epoch:  1 [ 2960/4654 (64%)]\tLoss: 0.393696\n",
      "Train Epoch:  1 [ 3000/4654 (64%)]\tLoss: 1.328582\n",
      "Train Epoch:  1 [ 3040/4654 (65%)]\tLoss: 1.935558\n",
      "Train Epoch:  1 [ 3080/4654 (66%)]\tLoss: 1.117286\n",
      "Train Epoch:  1 [ 3120/4654 (67%)]\tLoss: 0.457635\n",
      "Train Epoch:  1 [ 3160/4654 (68%)]\tLoss: 0.876890\n",
      "Train Epoch:  1 [ 3200/4654 (69%)]\tLoss: 0.990440\n",
      "Train Epoch:  1 [ 3240/4654 (70%)]\tLoss: 0.810956\n",
      "Train Epoch:  1 [ 3280/4654 (70%)]\tLoss: 0.729803\n",
      "Train Epoch:  1 [ 3320/4654 (71%)]\tLoss: 0.742933\n",
      "Train Epoch:  1 [ 3360/4654 (72%)]\tLoss: 0.856130\n",
      "Train Epoch:  1 [ 3400/4654 (73%)]\tLoss: 1.879467\n",
      "Train Epoch:  1 [ 3440/4654 (74%)]\tLoss: 3.020707\n",
      "Train Epoch:  1 [ 3480/4654 (75%)]\tLoss: 0.848043\n",
      "Train Epoch:  1 [ 3520/4654 (76%)]\tLoss: 0.620240\n",
      "Train Epoch:  1 [ 3560/4654 (76%)]\tLoss: 1.728190\n",
      "Train Epoch:  1 [ 3600/4654 (77%)]\tLoss: 2.443152\n",
      "Train Epoch:  1 [ 3640/4654 (78%)]\tLoss: 0.191044\n",
      "Train Epoch:  1 [ 3680/4654 (79%)]\tLoss: 1.561945\n",
      "Train Epoch:  1 [ 3720/4654 (80%)]\tLoss: 1.734286\n",
      "Train Epoch:  1 [ 3760/4654 (81%)]\tLoss: 0.995342\n",
      "Train Epoch:  1 [ 3800/4654 (82%)]\tLoss: 0.098020\n",
      "Train Epoch:  1 [ 3840/4654 (82%)]\tLoss: 0.703614\n",
      "Train Epoch:  1 [ 3880/4654 (83%)]\tLoss: 0.586609\n",
      "Train Epoch:  1 [ 3920/4654 (84%)]\tLoss: 0.695055\n",
      "Train Epoch:  1 [ 3960/4654 (85%)]\tLoss: 0.251066\n",
      "Train Epoch:  1 [ 4000/4654 (86%)]\tLoss: 0.941381\n",
      "Train Epoch:  1 [ 4040/4654 (87%)]\tLoss: 1.364604\n",
      "Train Epoch:  1 [ 4080/4654 (88%)]\tLoss: 0.931512\n",
      "Train Epoch:  1 [ 4120/4654 (88%)]\tLoss: 1.290700\n",
      "Train Epoch:  1 [ 4160/4654 (89%)]\tLoss: 2.566026\n",
      "Train Epoch:  1 [ 4200/4654 (90%)]\tLoss: 0.759780\n",
      "Train Epoch:  1 [ 4240/4654 (91%)]\tLoss: 1.049194\n",
      "Train Epoch:  1 [ 4280/4654 (92%)]\tLoss: 0.258525\n",
      "Train Epoch:  1 [ 4320/4654 (93%)]\tLoss: 1.259721\n",
      "Train Epoch:  1 [ 4360/4654 (94%)]\tLoss: 0.810467\n",
      "Train Epoch:  1 [ 4400/4654 (95%)]\tLoss: 0.508666\n",
      "Train Epoch:  1 [ 4440/4654 (95%)]\tLoss: 0.098853\n",
      "Train Epoch:  1 [ 4480/4654 (96%)]\tLoss: 2.085300\n",
      "Train Epoch:  1 [ 4520/4654 (97%)]\tLoss: 0.851532\n",
      "Train Epoch:  1 [ 4560/4654 (98%)]\tLoss: 1.840986\n",
      "Train Epoch:  1 [ 4600/4654 (99%)]\tLoss: 1.613215\n",
      "Train Epoch:  1 [ 4640/4654 (100%)]\tLoss: 0.463260\n",
      "\n",
      "Test set: Average loss: 0.3932, Accuracy: 1361/1552 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, n)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    train(model, device, criterion, train_loader, optimizer, epoch)\n",
    "    test(model, device, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
