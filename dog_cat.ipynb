{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "train_set = datasets.ImageFolder(root='data/001/train',transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=8)\n",
    "\n",
    "test_set = datasets.ImageFolder(root='data/001/test',transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, criterion, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {:2d} [{:5d}/{} ({:2.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, criterion, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target).item() \n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/markshi/.torch/models/resnet50-19c8e357.pth\n",
      "102502400it [00:05, 18118836.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  0 [    0/4654 (0.0%)]\tLoss: 2.166622\n",
      "Train Epoch:  0 [  400/4654 (8.6%)]\tLoss: 2.362605\n",
      "Train Epoch:  0 [  800/4654 (17.2%)]\tLoss: 2.050684\n",
      "Train Epoch:  0 [ 1200/4654 (25.8%)]\tLoss: 1.915527\n",
      "Train Epoch:  0 [ 1600/4654 (34.4%)]\tLoss: 1.999390\n",
      "Train Epoch:  0 [ 2000/4654 (43.0%)]\tLoss: 1.520494\n",
      "Train Epoch:  0 [ 2400/4654 (51.5%)]\tLoss: 1.498787\n",
      "Train Epoch:  0 [ 2800/4654 (60.1%)]\tLoss: 2.363690\n",
      "Train Epoch:  0 [ 3200/4654 (68.7%)]\tLoss: 1.520756\n",
      "Train Epoch:  0 [ 3600/4654 (77.3%)]\tLoss: 1.484714\n",
      "Train Epoch:  0 [ 4000/4654 (85.9%)]\tLoss: 1.526124\n",
      "Train Epoch:  0 [ 4400/4654 (94.5%)]\tLoss: 0.914816\n",
      "\n",
      "Test set: Average loss: 0.6011, Accuracy: 1234/1552 (80%)\n",
      "\n",
      "Train Epoch:  1 [    0/4654 (0.0%)]\tLoss: 1.476590\n",
      "Train Epoch:  1 [  400/4654 (8.6%)]\tLoss: 1.732650\n",
      "Train Epoch:  1 [  800/4654 (17.2%)]\tLoss: 1.758908\n",
      "Train Epoch:  1 [ 1200/4654 (25.8%)]\tLoss: 1.089572\n",
      "Train Epoch:  1 [ 1600/4654 (34.4%)]\tLoss: 0.636830\n",
      "Train Epoch:  1 [ 2000/4654 (43.0%)]\tLoss: 0.471474\n",
      "Train Epoch:  1 [ 2400/4654 (51.5%)]\tLoss: 1.085140\n",
      "Train Epoch:  1 [ 2800/4654 (60.1%)]\tLoss: 1.375531\n",
      "Train Epoch:  1 [ 3200/4654 (68.7%)]\tLoss: 2.210156\n",
      "Train Epoch:  1 [ 3600/4654 (77.3%)]\tLoss: 1.385079\n",
      "Train Epoch:  1 [ 4000/4654 (85.9%)]\tLoss: 1.230310\n",
      "Train Epoch:  1 [ 4400/4654 (94.5%)]\tLoss: 1.216424\n",
      "\n",
      "Test set: Average loss: 0.5207, Accuracy: 1283/1552 (83%)\n",
      "\n",
      "Train Epoch:  2 [    0/4654 (0.0%)]\tLoss: 1.403053\n",
      "Train Epoch:  2 [  400/4654 (8.6%)]\tLoss: 1.450463\n",
      "Train Epoch:  2 [  800/4654 (17.2%)]\tLoss: 0.293456\n",
      "Train Epoch:  2 [ 1200/4654 (25.8%)]\tLoss: 1.721830\n",
      "Train Epoch:  2 [ 1600/4654 (34.4%)]\tLoss: 0.652908\n",
      "Train Epoch:  2 [ 2000/4654 (43.0%)]\tLoss: 0.779141\n",
      "Train Epoch:  2 [ 2400/4654 (51.5%)]\tLoss: 0.475240\n",
      "Train Epoch:  2 [ 2800/4654 (60.1%)]\tLoss: 0.571643\n",
      "Train Epoch:  2 [ 3200/4654 (68.7%)]\tLoss: 2.381182\n",
      "Train Epoch:  2 [ 3600/4654 (77.3%)]\tLoss: 1.700439\n",
      "Train Epoch:  2 [ 4000/4654 (85.9%)]\tLoss: 0.311636\n",
      "Train Epoch:  2 [ 4400/4654 (94.5%)]\tLoss: 1.621980\n",
      "\n",
      "Test set: Average loss: 0.4635, Accuracy: 1284/1552 (83%)\n",
      "\n",
      "Train Epoch:  3 [    0/4654 (0.0%)]\tLoss: 0.724355\n",
      "Train Epoch:  3 [  400/4654 (8.6%)]\tLoss: 0.974049\n",
      "Train Epoch:  3 [  800/4654 (17.2%)]\tLoss: 1.023312\n",
      "Train Epoch:  3 [ 1200/4654 (25.8%)]\tLoss: 1.426466\n",
      "Train Epoch:  3 [ 1600/4654 (34.4%)]\tLoss: 0.572073\n",
      "Train Epoch:  3 [ 2000/4654 (43.0%)]\tLoss: 1.314429\n",
      "Train Epoch:  3 [ 2400/4654 (51.5%)]\tLoss: 2.075264\n",
      "Train Epoch:  3 [ 2800/4654 (60.1%)]\tLoss: 1.163817\n",
      "Train Epoch:  3 [ 3200/4654 (68.7%)]\tLoss: 1.357239\n",
      "Train Epoch:  3 [ 3600/4654 (77.3%)]\tLoss: 0.638698\n",
      "Train Epoch:  3 [ 4000/4654 (85.9%)]\tLoss: 1.395380\n",
      "Train Epoch:  3 [ 4400/4654 (94.5%)]\tLoss: 1.911309\n",
      "\n",
      "Test set: Average loss: 0.4313, Accuracy: 1333/1552 (86%)\n",
      "\n",
      "Train Epoch:  4 [    0/4654 (0.0%)]\tLoss: 1.638363\n",
      "Train Epoch:  4 [  400/4654 (8.6%)]\tLoss: 0.900128\n",
      "Train Epoch:  4 [  800/4654 (17.2%)]\tLoss: 1.362535\n",
      "Train Epoch:  4 [ 1200/4654 (25.8%)]\tLoss: 0.811494\n",
      "Train Epoch:  4 [ 1600/4654 (34.4%)]\tLoss: 0.745186\n",
      "Train Epoch:  4 [ 2000/4654 (43.0%)]\tLoss: 1.219346\n",
      "Train Epoch:  4 [ 2400/4654 (51.5%)]\tLoss: 1.328610\n",
      "Train Epoch:  4 [ 2800/4654 (60.1%)]\tLoss: 0.906188\n",
      "Train Epoch:  4 [ 3200/4654 (68.7%)]\tLoss: 1.921234\n",
      "Train Epoch:  4 [ 3600/4654 (77.3%)]\tLoss: 1.139591\n",
      "Train Epoch:  4 [ 4000/4654 (85.9%)]\tLoss: 0.820166\n",
      "Train Epoch:  4 [ 4400/4654 (94.5%)]\tLoss: 0.669367\n",
      "\n",
      "Test set: Average loss: 0.4457, Accuracy: 1273/1552 (82%)\n",
      "\n",
      "Train Epoch:  5 [    0/4654 (0.0%)]\tLoss: 0.301363\n",
      "Train Epoch:  5 [  400/4654 (8.6%)]\tLoss: 0.826496\n",
      "Train Epoch:  5 [  800/4654 (17.2%)]\tLoss: 0.986808\n",
      "Train Epoch:  5 [ 1200/4654 (25.8%)]\tLoss: 0.500249\n",
      "Train Epoch:  5 [ 1600/4654 (34.4%)]\tLoss: 1.083839\n",
      "Train Epoch:  5 [ 2000/4654 (43.0%)]\tLoss: 0.951293\n",
      "Train Epoch:  5 [ 2400/4654 (51.5%)]\tLoss: 0.954091\n",
      "Train Epoch:  5 [ 2800/4654 (60.1%)]\tLoss: 0.985717\n",
      "Train Epoch:  5 [ 3200/4654 (68.7%)]\tLoss: 0.707500\n",
      "Train Epoch:  5 [ 3600/4654 (77.3%)]\tLoss: 1.048072\n",
      "Train Epoch:  5 [ 4000/4654 (85.9%)]\tLoss: 0.676000\n",
      "Train Epoch:  5 [ 4400/4654 (94.5%)]\tLoss: 1.399730\n",
      "\n",
      "Test set: Average loss: 0.4175, Accuracy: 1314/1552 (85%)\n",
      "\n",
      "Train Epoch:  6 [    0/4654 (0.0%)]\tLoss: 1.403461\n",
      "Train Epoch:  6 [  400/4654 (8.6%)]\tLoss: 0.611750\n",
      "Train Epoch:  6 [  800/4654 (17.2%)]\tLoss: 1.285208\n",
      "Train Epoch:  6 [ 1200/4654 (25.8%)]\tLoss: 0.444886\n",
      "Train Epoch:  6 [ 1600/4654 (34.4%)]\tLoss: 1.454514\n",
      "Train Epoch:  6 [ 2000/4654 (43.0%)]\tLoss: 1.030428\n",
      "Train Epoch:  6 [ 2400/4654 (51.5%)]\tLoss: 0.529520\n",
      "Train Epoch:  6 [ 2800/4654 (60.1%)]\tLoss: 1.164416\n",
      "Train Epoch:  6 [ 3200/4654 (68.7%)]\tLoss: 0.787738\n",
      "Train Epoch:  6 [ 3600/4654 (77.3%)]\tLoss: 1.447836\n",
      "Train Epoch:  6 [ 4000/4654 (85.9%)]\tLoss: 1.484769\n",
      "Train Epoch:  6 [ 4400/4654 (94.5%)]\tLoss: 0.954049\n",
      "\n",
      "Test set: Average loss: 0.4041, Accuracy: 1328/1552 (86%)\n",
      "\n",
      "Train Epoch:  7 [    0/4654 (0.0%)]\tLoss: 0.733949\n",
      "Train Epoch:  7 [  400/4654 (8.6%)]\tLoss: 0.241278\n",
      "Train Epoch:  7 [  800/4654 (17.2%)]\tLoss: 1.003147\n",
      "Train Epoch:  7 [ 1200/4654 (25.8%)]\tLoss: 0.156126\n",
      "Train Epoch:  7 [ 1600/4654 (34.4%)]\tLoss: 1.519212\n",
      "Train Epoch:  7 [ 2000/4654 (43.0%)]\tLoss: 1.486737\n",
      "Train Epoch:  7 [ 2400/4654 (51.5%)]\tLoss: 0.675576\n",
      "Train Epoch:  7 [ 2800/4654 (60.1%)]\tLoss: 1.757503\n",
      "Train Epoch:  7 [ 3200/4654 (68.7%)]\tLoss: 0.980064\n",
      "Train Epoch:  7 [ 3600/4654 (77.3%)]\tLoss: 2.058980\n",
      "Train Epoch:  7 [ 4000/4654 (85.9%)]\tLoss: 0.533391\n",
      "Train Epoch:  7 [ 4400/4654 (94.5%)]\tLoss: 0.519109\n",
      "\n",
      "Test set: Average loss: 0.4021, Accuracy: 1354/1552 (87%)\n",
      "\n",
      "Train Epoch:  8 [    0/4654 (0.0%)]\tLoss: 2.199413\n",
      "Train Epoch:  8 [  400/4654 (8.6%)]\tLoss: 1.651908\n",
      "Train Epoch:  8 [  800/4654 (17.2%)]\tLoss: 1.087494\n",
      "Train Epoch:  8 [ 1200/4654 (25.8%)]\tLoss: 0.672882\n",
      "Train Epoch:  8 [ 1600/4654 (34.4%)]\tLoss: 1.892992\n",
      "Train Epoch:  8 [ 2000/4654 (43.0%)]\tLoss: 1.866251\n",
      "Train Epoch:  8 [ 2400/4654 (51.5%)]\tLoss: 1.090783\n",
      "Train Epoch:  8 [ 2800/4654 (60.1%)]\tLoss: 1.667701\n",
      "Train Epoch:  8 [ 3200/4654 (68.7%)]\tLoss: 0.710543\n",
      "Train Epoch:  8 [ 3600/4654 (77.3%)]\tLoss: 0.608455\n",
      "Train Epoch:  8 [ 4000/4654 (85.9%)]\tLoss: 0.865018\n",
      "Train Epoch:  8 [ 4400/4654 (94.5%)]\tLoss: 0.367525\n",
      "\n",
      "Test set: Average loss: 0.3787, Accuracy: 1368/1552 (88%)\n",
      "\n",
      "Train Epoch:  9 [    0/4654 (0.0%)]\tLoss: 1.933592\n",
      "Train Epoch:  9 [  400/4654 (8.6%)]\tLoss: 1.823987\n",
      "Train Epoch:  9 [  800/4654 (17.2%)]\tLoss: 1.312478\n",
      "Train Epoch:  9 [ 1200/4654 (25.8%)]\tLoss: 0.400621\n",
      "Train Epoch:  9 [ 1600/4654 (34.4%)]\tLoss: 1.816300\n",
      "Train Epoch:  9 [ 2000/4654 (43.0%)]\tLoss: 0.787326\n",
      "Train Epoch:  9 [ 2400/4654 (51.5%)]\tLoss: 0.314281\n",
      "Train Epoch:  9 [ 2800/4654 (60.1%)]\tLoss: 1.139282\n",
      "Train Epoch:  9 [ 3200/4654 (68.7%)]\tLoss: 0.683442\n",
      "Train Epoch:  9 [ 3600/4654 (77.3%)]\tLoss: 1.730067\n",
      "Train Epoch:  9 [ 4000/4654 (85.9%)]\tLoss: 1.087366\n",
      "Train Epoch:  9 [ 4400/4654 (94.5%)]\tLoss: 1.080642\n",
      "\n",
      "Test set: Average loss: 0.3871, Accuracy: 1354/1552 (87%)\n",
      "\n",
      "Train Epoch: 10 [    0/4654 (0.0%)]\tLoss: 0.896456\n",
      "Train Epoch: 10 [  400/4654 (8.6%)]\tLoss: 1.528168\n",
      "Train Epoch: 10 [  800/4654 (17.2%)]\tLoss: 1.528643\n",
      "Train Epoch: 10 [ 1200/4654 (25.8%)]\tLoss: 2.905119\n",
      "Train Epoch: 10 [ 1600/4654 (34.4%)]\tLoss: 0.693878\n",
      "Train Epoch: 10 [ 2000/4654 (43.0%)]\tLoss: 1.485391\n",
      "Train Epoch: 10 [ 2400/4654 (51.5%)]\tLoss: 1.411072\n",
      "Train Epoch: 10 [ 2800/4654 (60.1%)]\tLoss: 0.997001\n",
      "Train Epoch: 10 [ 3200/4654 (68.7%)]\tLoss: 0.806952\n",
      "Train Epoch: 10 [ 3600/4654 (77.3%)]\tLoss: 0.286144\n",
      "Train Epoch: 10 [ 4000/4654 (85.9%)]\tLoss: 0.656847\n",
      "Train Epoch: 10 [ 4400/4654 (94.5%)]\tLoss: 1.635220\n",
      "\n",
      "Test set: Average loss: 0.4053, Accuracy: 1337/1552 (86%)\n",
      "\n",
      "Train Epoch: 11 [    0/4654 (0.0%)]\tLoss: 1.321478\n",
      "Train Epoch: 11 [  400/4654 (8.6%)]\tLoss: 2.628701\n",
      "Train Epoch: 11 [  800/4654 (17.2%)]\tLoss: 0.760569\n",
      "Train Epoch: 11 [ 1200/4654 (25.8%)]\tLoss: 1.115883\n",
      "Train Epoch: 11 [ 1600/4654 (34.4%)]\tLoss: 1.180890\n",
      "Train Epoch: 11 [ 2000/4654 (43.0%)]\tLoss: 1.693333\n",
      "Train Epoch: 11 [ 2400/4654 (51.5%)]\tLoss: 1.459649\n",
      "Train Epoch: 11 [ 2800/4654 (60.1%)]\tLoss: 2.052223\n",
      "Train Epoch: 11 [ 3200/4654 (68.7%)]\tLoss: 0.786155\n",
      "Train Epoch: 11 [ 3600/4654 (77.3%)]\tLoss: 1.273018\n",
      "Train Epoch: 11 [ 4000/4654 (85.9%)]\tLoss: 1.573781\n",
      "Train Epoch: 11 [ 4400/4654 (94.5%)]\tLoss: 0.801868\n",
      "\n",
      "Test set: Average loss: 0.3709, Accuracy: 1365/1552 (88%)\n",
      "\n",
      "Train Epoch: 12 [    0/4654 (0.0%)]\tLoss: 1.795215\n",
      "Train Epoch: 12 [  400/4654 (8.6%)]\tLoss: 0.755820\n",
      "Train Epoch: 12 [  800/4654 (17.2%)]\tLoss: 1.638317\n",
      "Train Epoch: 12 [ 1200/4654 (25.8%)]\tLoss: 0.983091\n",
      "Train Epoch: 12 [ 1600/4654 (34.4%)]\tLoss: 2.352968\n",
      "Train Epoch: 12 [ 2000/4654 (43.0%)]\tLoss: 1.290606\n",
      "Train Epoch: 12 [ 2400/4654 (51.5%)]\tLoss: 2.576519\n",
      "Train Epoch: 12 [ 2800/4654 (60.1%)]\tLoss: 0.904005\n",
      "Train Epoch: 12 [ 3200/4654 (68.7%)]\tLoss: 0.627719\n",
      "Train Epoch: 12 [ 3600/4654 (77.3%)]\tLoss: 1.992919\n",
      "Train Epoch: 12 [ 4000/4654 (85.9%)]\tLoss: 0.895435\n",
      "Train Epoch: 12 [ 4400/4654 (94.5%)]\tLoss: 0.985852\n",
      "\n",
      "Test set: Average loss: 0.3579, Accuracy: 1364/1552 (88%)\n",
      "\n",
      "Train Epoch: 13 [    0/4654 (0.0%)]\tLoss: 1.460445\n",
      "Train Epoch: 13 [  400/4654 (8.6%)]\tLoss: 1.522564\n",
      "Train Epoch: 13 [  800/4654 (17.2%)]\tLoss: 1.326155\n",
      "Train Epoch: 13 [ 1200/4654 (25.8%)]\tLoss: 1.030436\n",
      "Train Epoch: 13 [ 1600/4654 (34.4%)]\tLoss: 1.865821\n",
      "Train Epoch: 13 [ 2000/4654 (43.0%)]\tLoss: 1.777458\n",
      "Train Epoch: 13 [ 2400/4654 (51.5%)]\tLoss: 1.075195\n",
      "Train Epoch: 13 [ 2800/4654 (60.1%)]\tLoss: 1.515511\n",
      "Train Epoch: 13 [ 3200/4654 (68.7%)]\tLoss: 0.473273\n",
      "Train Epoch: 13 [ 3600/4654 (77.3%)]\tLoss: 0.953037\n",
      "Train Epoch: 13 [ 4000/4654 (85.9%)]\tLoss: 1.179473\n",
      "Train Epoch: 13 [ 4400/4654 (94.5%)]\tLoss: 1.396117\n",
      "\n",
      "Test set: Average loss: 0.3608, Accuracy: 1375/1552 (89%)\n",
      "\n",
      "Train Epoch: 14 [    0/4654 (0.0%)]\tLoss: 1.329619\n",
      "Train Epoch: 14 [  400/4654 (8.6%)]\tLoss: 1.316288\n",
      "Train Epoch: 14 [  800/4654 (17.2%)]\tLoss: 0.355387\n",
      "Train Epoch: 14 [ 1200/4654 (25.8%)]\tLoss: 1.255494\n",
      "Train Epoch: 14 [ 1600/4654 (34.4%)]\tLoss: 1.451247\n",
      "Train Epoch: 14 [ 2000/4654 (43.0%)]\tLoss: 0.035175\n",
      "Train Epoch: 14 [ 2400/4654 (51.5%)]\tLoss: 0.673914\n",
      "Train Epoch: 14 [ 2800/4654 (60.1%)]\tLoss: 1.851502\n",
      "Train Epoch: 14 [ 3200/4654 (68.7%)]\tLoss: 1.241302\n",
      "Train Epoch: 14 [ 3600/4654 (77.3%)]\tLoss: 0.549654\n",
      "Train Epoch: 14 [ 4000/4654 (85.9%)]\tLoss: 0.697710\n",
      "Train Epoch: 14 [ 4400/4654 (94.5%)]\tLoss: 0.871086\n",
      "\n",
      "Test set: Average loss: 0.3431, Accuracy: 1376/1552 (89%)\n",
      "\n",
      "Train Epoch: 15 [    0/4654 (0.0%)]\tLoss: 1.153817\n",
      "Train Epoch: 15 [  400/4654 (8.6%)]\tLoss: 0.064799\n",
      "Train Epoch: 15 [  800/4654 (17.2%)]\tLoss: 0.496294\n",
      "Train Epoch: 15 [ 1200/4654 (25.8%)]\tLoss: 0.955568\n",
      "Train Epoch: 15 [ 1600/4654 (34.4%)]\tLoss: 0.952665\n",
      "Train Epoch: 15 [ 2000/4654 (43.0%)]\tLoss: 0.816218\n",
      "Train Epoch: 15 [ 2400/4654 (51.5%)]\tLoss: 1.942927\n",
      "Train Epoch: 15 [ 2800/4654 (60.1%)]\tLoss: 1.462257\n",
      "Train Epoch: 15 [ 3200/4654 (68.7%)]\tLoss: 1.209920\n",
      "Train Epoch: 15 [ 3600/4654 (77.3%)]\tLoss: 0.929196\n",
      "Train Epoch: 15 [ 4000/4654 (85.9%)]\tLoss: 1.008542\n",
      "Train Epoch: 15 [ 4400/4654 (94.5%)]\tLoss: 0.308970\n",
      "\n",
      "Test set: Average loss: 0.3552, Accuracy: 1366/1552 (88%)\n",
      "\n",
      "Train Epoch: 16 [    0/4654 (0.0%)]\tLoss: 1.501013\n",
      "Train Epoch: 16 [  400/4654 (8.6%)]\tLoss: 1.269109\n",
      "Train Epoch: 16 [  800/4654 (17.2%)]\tLoss: 0.259152\n",
      "Train Epoch: 16 [ 1200/4654 (25.8%)]\tLoss: 2.495710\n",
      "Train Epoch: 16 [ 1600/4654 (34.4%)]\tLoss: 0.609119\n",
      "Train Epoch: 16 [ 2000/4654 (43.0%)]\tLoss: 2.118414\n",
      "Train Epoch: 16 [ 2400/4654 (51.5%)]\tLoss: 0.675651\n",
      "Train Epoch: 16 [ 2800/4654 (60.1%)]\tLoss: 1.073619\n",
      "Train Epoch: 16 [ 3200/4654 (68.7%)]\tLoss: 1.926262\n",
      "Train Epoch: 16 [ 3600/4654 (77.3%)]\tLoss: 1.158992\n",
      "Train Epoch: 16 [ 4000/4654 (85.9%)]\tLoss: 1.273068\n",
      "Train Epoch: 16 [ 4400/4654 (94.5%)]\tLoss: 0.903456\n",
      "\n",
      "Test set: Average loss: 0.3385, Accuracy: 1384/1552 (89%)\n",
      "\n",
      "Train Epoch: 17 [    0/4654 (0.0%)]\tLoss: 0.962681\n",
      "Train Epoch: 17 [  400/4654 (8.6%)]\tLoss: 0.890226\n",
      "Train Epoch: 17 [  800/4654 (17.2%)]\tLoss: 1.181023\n",
      "Train Epoch: 17 [ 1200/4654 (25.8%)]\tLoss: 0.597981\n",
      "Train Epoch: 17 [ 1600/4654 (34.4%)]\tLoss: 1.483152\n",
      "Train Epoch: 17 [ 2000/4654 (43.0%)]\tLoss: 1.898433\n",
      "Train Epoch: 17 [ 2400/4654 (51.5%)]\tLoss: 1.719421\n",
      "Train Epoch: 17 [ 2800/4654 (60.1%)]\tLoss: 0.432063\n",
      "Train Epoch: 17 [ 3200/4654 (68.7%)]\tLoss: 1.656225\n",
      "Train Epoch: 17 [ 3600/4654 (77.3%)]\tLoss: 0.790966\n",
      "Train Epoch: 17 [ 4000/4654 (85.9%)]\tLoss: 0.657250\n",
      "Train Epoch: 17 [ 4400/4654 (94.5%)]\tLoss: 1.288993\n",
      "\n",
      "Test set: Average loss: 0.3185, Accuracy: 1397/1552 (90%)\n",
      "\n",
      "Train Epoch: 18 [    0/4654 (0.0%)]\tLoss: 0.637044\n",
      "Train Epoch: 18 [  400/4654 (8.6%)]\tLoss: 1.918096\n",
      "Train Epoch: 18 [  800/4654 (17.2%)]\tLoss: 0.640776\n",
      "Train Epoch: 18 [ 1200/4654 (25.8%)]\tLoss: 1.067534\n",
      "Train Epoch: 18 [ 1600/4654 (34.4%)]\tLoss: 1.405167\n",
      "Train Epoch: 18 [ 2000/4654 (43.0%)]\tLoss: 0.372394\n",
      "Train Epoch: 18 [ 2400/4654 (51.5%)]\tLoss: 0.708438\n",
      "Train Epoch: 18 [ 2800/4654 (60.1%)]\tLoss: 0.792067\n",
      "Train Epoch: 18 [ 3200/4654 (68.7%)]\tLoss: 1.894168\n",
      "Train Epoch: 18 [ 3600/4654 (77.3%)]\tLoss: 0.492685\n",
      "Train Epoch: 18 [ 4000/4654 (85.9%)]\tLoss: 2.322798\n",
      "Train Epoch: 18 [ 4400/4654 (94.5%)]\tLoss: 1.170758\n",
      "\n",
      "Test set: Average loss: 0.3257, Accuracy: 1395/1552 (90%)\n",
      "\n",
      "Train Epoch: 19 [    0/4654 (0.0%)]\tLoss: 1.553132\n",
      "Train Epoch: 19 [  400/4654 (8.6%)]\tLoss: 1.355122\n",
      "Train Epoch: 19 [  800/4654 (17.2%)]\tLoss: 0.755976\n",
      "Train Epoch: 19 [ 1200/4654 (25.8%)]\tLoss: 0.887374\n",
      "Train Epoch: 19 [ 1600/4654 (34.4%)]\tLoss: 4.358720\n",
      "Train Epoch: 19 [ 2000/4654 (43.0%)]\tLoss: 1.207200\n",
      "Train Epoch: 19 [ 2400/4654 (51.5%)]\tLoss: 0.747339\n",
      "Train Epoch: 19 [ 2800/4654 (60.1%)]\tLoss: 0.667450\n",
      "Train Epoch: 19 [ 3200/4654 (68.7%)]\tLoss: 2.127043\n",
      "Train Epoch: 19 [ 3600/4654 (77.3%)]\tLoss: 1.286222\n",
      "Train Epoch: 19 [ 4000/4654 (85.9%)]\tLoss: 1.216476\n",
      "Train Epoch: 19 [ 4400/4654 (94.5%)]\tLoss: 1.676329\n",
      "\n",
      "Test set: Average loss: 0.3304, Accuracy: 1397/1552 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "n = len(np.unique(train_set.targets))\n",
    "classifier = nn.Sequential(nn.Linear(model.fc.in_features,128),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(0.2),\n",
    "                          nn.Linear(128,64),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(0.2),\n",
    "                          nn.Linear(64,n))\n",
    "model.fc = classifier\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    train(model, device, criterion, train_loader, optimizer, epoch)\n",
    "    test(model, device, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3304, Accuracy: 1397/1552 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, device, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 4, 7]\n",
      "[3, 2, 4, 2]\n",
      "[7, 1, 4, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 7, 4, 7, 3, 2, 4, 2, 7, 1, 4, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst = []\n",
    "with torch.no_grad():\n",
    "    for i, v in enumerate(test_loader):\n",
    "        if i==3:\n",
    "            break\n",
    "        data, target = v\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        print(list(pred.cpu().numpy()))\n",
    "        rst+=list(pred.cpu().numpy())\n",
    "rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2)\n",
       "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
